{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad1a2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6e459a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed0ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bc9e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,sys\n",
    "from pathlib import Path\n",
    "import json \n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)-7s %(message)s',\n",
    "                    stream=sys.stderr, level=logging.INFO)\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.INFO)\n",
    "\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "\n",
    "#General ML \n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, silhouette_score,confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2,f_classif\n",
    "from modules.clustering_helpers import select_labeled_samples\n",
    "#In-house Module Imports\n",
    "from config import Configuration \n",
    "from datasets import EclipseSampledDataset, VoltaSampledDataset\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from utils import *\n",
    "import hdbscan\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2c01c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5a38cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 06:00:53,402 INFO    Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
     ]
    }
   ],
   "source": [
    "### new ML models\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "354fe0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 06:01:21,721 WARNING Are you sure that you are: aksar?\n",
      "2022-05-06 06:01:21,722 WARNING Results will be generated in tuning_results, double check please!\n"
     ]
    }
   ],
   "source": [
    "### Settings\n",
    "user = \"aksar\"\n",
    "logging.warning(f'Are you sure that you are: {user}?')\n",
    "OUTPUT_DIR = f'/projectnb/peaclab-mon/{user}/active_learning_experiments'\n",
    "classifier_name = 'rf'\n",
    "num_samples_per_pair = 1\n",
    "NUM_FEATURE  = 2000\n",
    "SYSTEM = 'volta'\n",
    "FE_NAME = 'tsfresh'\n",
    "EXP_NAME  = 'tsfresh_experiments'\n",
    "CV_INDEX = 0\n",
    "FS_NAME = \"CHI\"\n",
    "FEATURE_SELECTION = False\n",
    "SCALER = 'None' #For now, do the scaling inside the notebook, then you can move that to the class function\n",
    "MODEL_CONFIG = 'tuning_results' #rf_tuncer or rf_tuncer_worst_case\n",
    "logging.warning('Results will be generated in {}, double check please!'.format(MODEL_CONFIG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55e7c412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 06:01:23,191 WARNING You set windowing False, but you are trying to define window_size parameter, it is automatically set to 0. Please double check.\n",
      "2022-05-06 06:01:23,192 INFO    Setting directory names\n",
      "2022-05-06 06:01:23,198 INFO    Model config folder already exists, be careful, otherwise it will overwrite!\n",
      "2022-05-06 06:01:23,202 INFO    Saving configuration as CSV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The configuration used for this run:\n",
      "# {'cv_fold': 0,\n",
      "#  'exp_name': 'tsfresh_experiments',\n",
      "#  'experiment_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments/volta/tsfresh_experiments'),\n",
      "#  'feature_extract': False,\n",
      "#  'feature_select': False,\n",
      "#  'hdf_data_path': PosixPath('/projectnb/peaclab-mon/aksar/datasets/tpds_data_hdfs'),\n",
      "#  'metadata_path': None,\n",
      "#  'model_config': 'tuning_results',\n",
      "#  'model_config_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments/volta/tsfresh_experiments/CV_0/tuning_results'),\n",
      "#  'model_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments/volta/tsfresh_experiments/CV_0/tuning_results/model'),\n",
      "#  'num_split': 5,\n",
      "#  'operation': 'read',\n",
      "#  'output_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments/volta'),\n",
      "#  'plots_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments/volta/tsfresh_experiments/CV_0/tuning_results/model/plots'),\n",
      "#  'processed_ldms_data_path': None,\n",
      "#  'raw_ldms_data_path': None,\n",
      "#  'results_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments/volta/tsfresh_experiments/CV_0/tuning_results/results'),\n",
      "#  'runtime_testing_dir': None,\n",
      "#  'system': 'volta',\n",
      "#  'window_size': 0,\n",
      "#  'windowing': False}\n"
     ]
    }
   ],
   "source": [
    "conf = Configuration(ipython=True,\n",
    "                     overrides={\n",
    "                         'output_dir': Path(OUTPUT_DIR), #change\n",
    "                         'system' : SYSTEM,\n",
    "                         'exp_name':EXP_NAME,                                                  \n",
    "                         'cv_fold':CV_INDEX, \n",
    "                         'model_config': MODEL_CONFIG,\n",
    "                     })\n",
    "\n",
    "with open(str(conf['experiment_dir']) + '/anom_dict.json') as f:\n",
    "    ANOM_DICT = json.load(f)\n",
    "with open(str(conf['experiment_dir']) + '/app_dict.json') as f:\n",
    "    APP_DICT = json.load(f) \n",
    "    \n",
    "APP_REVERSE_DICT = {}\n",
    "for app_name, app_encoding in APP_DICT.items():\n",
    "    APP_REVERSE_DICT[app_encoding] = app_name    \n",
    "\n",
    "ANOM_REVERSE_DICT = {}\n",
    "for anom_name, anom_encoding in ANOM_DICT.items():\n",
    "    ANOM_REVERSE_DICT[anom_encoding] = anom_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6120f31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 06:01:29,356 INFO    BaseDataset Class Initialization\n",
      "2022-05-06 06:01:29,357 INFO    HPCDataset Class Initialization\n",
      "2022-05-06 06:01:29,358 INFO    VoltaSampledDataset Class Initialization\n",
      "2022-05-06 06:04:06,102 INFO    Train data shape (6326, 102311)\n",
      "2022-05-06 06:04:06,121 INFO    Train label shape (6326, 2)\n",
      "2022-05-06 06:04:06,122 INFO    Test data shape (14589, 102311)\n",
      "2022-05-06 06:04:06,122 INFO    Test label shape (14589, 2)\n",
      "2022-05-06 06:04:06,124 WARNING Beware that no scaling method is applied\n",
      "2022-05-06 06:04:57,739 INFO    Train data shape (6326, 99169)\n",
      "2022-05-06 06:04:57,740 INFO    Train label shape (6326, 4)\n",
      "2022-05-06 06:04:57,741 INFO    Test data shape (14589, 99169)\n",
      "2022-05-06 06:04:57,741 INFO    Test label shape (14589, 4)\n",
      "2022-05-06 06:04:57,744 INFO    Train data label dist: \n",
      "0    5694\n",
      "2     159\n",
      "4     159\n",
      "1     158\n",
      "3     156\n",
      "Name: anom, dtype: int64\n",
      "2022-05-06 06:04:57,748 INFO    Test data label dist: \n",
      "0    13286\n",
      "1      332\n",
      "2      326\n",
      "3      324\n",
      "4      321\n",
      "Name: anom, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if SYSTEM == \"eclipse\":\n",
    "        eclipseDataset = EclipseSampledDataset(conf)\n",
    "        train_data, train_label, test_data, test_label = eclipseDataset.load_dataset(\n",
    "            cv_fold=CV_INDEX,\n",
    "            scaler=SCALER,\n",
    "            borghesi=False,\n",
    "            mvts=True if FE_NAME == \"mvts\" else False,\n",
    "            tsfresh=True if FE_NAME == \"tsfresh\" else False,\n",
    "        )\n",
    "\n",
    "elif SYSTEM == \"volta\":\n",
    "    voltaDataset = VoltaSampledDataset(conf)\n",
    "    train_data, train_label, test_data, test_label = voltaDataset.load_dataset(\n",
    "        cv_fold=CV_INDEX,\n",
    "        scaler=SCALER,\n",
    "        borghesi=False,\n",
    "        mvts=True if FE_NAME == \"mvts\" else False,\n",
    "        tsfresh=True if FE_NAME == \"tsfresh\" else False,\n",
    "    )\n",
    "\n",
    "assert list(train_data.index) == list(train_label.index)  # check the order of the labels\n",
    "assert list(test_data.index) == list(test_label.index)  # check the order of the labels\n",
    "\n",
    "if FEATURE_SELECTION:\n",
    "    selected_features = pd.read_csv(conf[\"experiment_dir\"] / \"selected_features.csv\")\n",
    "    train_data = train_data[list(selected_features[\"0\"].values)]\n",
    "    test_data = test_data[list(selected_features[\"0\"].values)]\n",
    "\n",
    "train_label[\"anom_names\"] = train_label.apply(lambda x: ANOM_REVERSE_DICT[x[\"anom\"]], axis=1)\n",
    "train_label[\"app_names\"] = train_label[\"app\"].apply(lambda x: APP_REVERSE_DICT[x])\n",
    "test_label[\"anom_names\"] = test_label.apply(lambda x: ANOM_REVERSE_DICT[x[\"anom\"]], axis=1)\n",
    "test_label[\"app_names\"] = test_label[\"app\"].apply(lambda x: APP_REVERSE_DICT[x])\n",
    "\n",
    "all_data = pd.concat([train_data, test_data])\n",
    "all_data = all_data.dropna(axis=1, how=\"any\")\n",
    "all_label = pd.concat([train_label, test_label])\n",
    "\n",
    "train_data = all_data.loc[train_label.index]\n",
    "test_data = all_data.loc[test_label.index]\n",
    "\n",
    "logging.info(\"Train data shape %s\", train_data.shape)\n",
    "logging.info(\"Train label shape %s\", train_label.shape)\n",
    "logging.info(\"Test data shape %s\", test_data.shape)\n",
    "logging.info(\"Test label shape %s\", test_label.shape)\n",
    "\n",
    "logging.info(\"Train data label dist: \\n%s\", train_label[\"anom\"].value_counts())\n",
    "logging.info(\"Test data label dist: \\n%s\", test_label[\"anom\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d39a29ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 06:05:38,705 INFO    (6326, 2000)\n",
      "2022-05-06 06:05:38,706 INFO    (14589, 2000)\n"
     ]
    }
   ],
   "source": [
    "SCALER = \"MinMax\"\n",
    "\n",
    "if SCALER == \"MinMax\":\n",
    "\n",
    "    minmax_scaler = MinMaxScaler().fit(train_data)\n",
    "    train_data = pd.DataFrame(\n",
    "        minmax_scaler.transform(train_data), columns=train_data.columns, index=train_data.index\n",
    "    )\n",
    "    test_data = pd.DataFrame(\n",
    "        minmax_scaler.transform(test_data), columns=test_data.columns, index=test_data.index\n",
    "    )\n",
    "\n",
    "elif SCALER == \"Standard\":\n",
    "\n",
    "    # Standardize data (per feature Z-normalization, i.e. zero-mean and unit variance)\n",
    "    scaler = StandardScaler().fit(train_data)\n",
    "    train_data = pd.DataFrame(\n",
    "        scaler.transform(train_data), columns=train_data.columns, index=train_data.index\n",
    "    )\n",
    "    test_data = pd.DataFrame(\n",
    "        scaler.transform(test_data), columns=test_data.columns, index=test_data.index\n",
    "    )\n",
    "\n",
    "# Implement new feature selection strategies below\n",
    "if FS_NAME == \"CHI\":\n",
    "\n",
    "    selector = SelectKBest(chi2, k=NUM_FEATURE)\n",
    "    selector.fit(train_data, train_label[\"anom\"])\n",
    "    train_data = train_data[train_data.columns[selector.get_support(indices=True)]]\n",
    "    selected_columns = train_data.columns\n",
    "    test_data = test_data[test_data.columns & selected_columns]\n",
    "\n",
    "elif FS_NAME == \"TSFRESH\":\n",
    "    logging.warning(\n",
    "        \"NUM_FEATURE parameter will be overwritten by the automatic selection process\"\n",
    "    )\n",
    "\n",
    "    y_train = train_label[\"anom\"]\n",
    "    X_train = train_data\n",
    "\n",
    "    relevant_features = set()\n",
    "\n",
    "    for label in y_train.unique():\n",
    "        y_train_binary = y_train == label\n",
    "        X_train_filtered = tsfresh.select_features(X_train, y_train_binary)\n",
    "        print(\n",
    "            \"Number of relevant features for class {}: {}/{}\".format(\n",
    "                label, X_train_filtered.shape[1], X_train.shape[1]\n",
    "            )\n",
    "        )\n",
    "        relevant_features = relevant_features.union(set(X_train_filtered.columns))\n",
    "    train_data = train_data[relevant_features]\n",
    "    test_data = test_data[relevant_features]\n",
    "    NUM_FEATURE = len(relevant_features)\n",
    "\n",
    "elif FS_NAME == \"NONE\":\n",
    "    logging.info(\"No feature selection strategy is specified, will be using all features\")\n",
    "    NUM_FEATURE = len(train_data.columns)\n",
    "\n",
    "logging.info(train_data.shape)\n",
    "logging.info(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48e63aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 06:05:38,809 INFO    Labeled data label dist: \n",
      "2    12\n",
      "4    11\n",
      "3    11\n",
      "1    11\n",
      "0    11\n",
      "Name: anom, dtype: int64\n",
      "2022-05-06 06:05:38,812 INFO    Unlabeled data label dist: \n",
      "0    5683\n",
      "4     148\n",
      "2     147\n",
      "1     147\n",
      "3     145\n",
      "Name: anom, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labeled_train_label = pd.read_csv(\n",
    "    conf[\"experiment_dir\"]\n",
    "    / f\"CV_{CV_INDEX}\"\n",
    "    / f\"labeled_train_label_{num_samples_per_pair}.csv\",\n",
    "    index_col=[\"node_id\"],\n",
    ")\n",
    "labeled_test_label = pd.read_csv(\n",
    "    conf[\"experiment_dir\"]\n",
    "    / f\"CV_{CV_INDEX}\"\n",
    "    / f\"labeled_test_label_{num_samples_per_pair}.csv\",\n",
    "    index_col=[\"node_id\"],\n",
    ")\n",
    "node_indices_labeled = list(labeled_train_label[\"anom\"].index.values)\n",
    "\n",
    "logging.info(\"Labeled data label dist: \\n%s\", labeled_train_label[\"anom\"].value_counts())\n",
    "logging.info(\"Unlabeled data label dist: \\n%s\", labeled_test_label[\"anom\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0df5f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a new column for label status\n",
    "node_indices_unlabeled = []\n",
    "for node in train_label.index:\n",
    "    if node not in node_indices_labeled:\n",
    "        node_indices_unlabeled.append(node)\n",
    "train_label[\"label_status\"] = train_label[\"anom\"]  # for the full data case\n",
    "train_label[\"label_status\"] = np.where(\n",
    "    train_label.index.get_level_values(\"node_id\").isin(node_indices_unlabeled),\n",
    "    -1,\n",
    "    train_label[\"label_status\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37d2b4cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label_status'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/project/peaclab-mon/tsfresh_monitoring_venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label_status'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2fdba8ee606a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# initial_labeled_pool contains one sample from each application anomaly pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minitial_labeled_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_status\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Active learning or random sampling will be querying from the same pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minitial_unlabeled_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_status\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/peaclab-mon/tsfresh_monitoring_venv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/peaclab-mon/tsfresh_monitoring_venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label_status'"
     ]
    }
   ],
   "source": [
    "# initial_labeled_pool contains one sample from each application anomaly pair\n",
    "initial_labeled_pool = train_label[(train_label[\"label_status\"] != -1)]\n",
    "# Active learning or random sampling will be querying from the same pool\n",
    "initial_unlabeled_pool = train_label[(train_label[\"label_status\"] == -1)]\n",
    "\n",
    "if classifier_name == \"rf\":\n",
    "    selected_classifier = RandomForestClassifier()\n",
    "elif classifier_name == \"lr\":\n",
    "    selected_classifier = LogisticRegression()\n",
    "else:\n",
    "    selected_classifier = RandomForestClassifier()\n",
    "\n",
    "scores = pd.DataFrame()\n",
    "\n",
    "all_app_names = list(APP_DICT.keys())\n",
    "selected_apps = dict.fromkeys(all_app_names, 0)\n",
    "selected_anoms = dict.fromkeys(list(ANOM_REVERSE_DICT.keys()), 0)\n",
    "\n",
    "# Create the label and data for the starting condition composed of selected apps\n",
    "y_initial = initial_labeled_pool\n",
    "x_initial = train_data[train_data.index.get_level_values(\"node_id\").isin(y_initial.index)]\n",
    "y_initial = y_initial[\"anom\"].to_numpy()\n",
    "\"\"\"x_initial = x_initial.to_numpy()\n",
    "\n",
    "x_unlabeled = train_data[\n",
    "    train_data.index.get_level_values(\"node_id\").isin(initial_unlabeled_pool.index)\n",
    "]\n",
    "y_unlabeled = initial_unlabeled_pool\n",
    "x_unlabeled = x_unlabeled.to_numpy()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cfb0a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = { \n",
    "            'n_estimators': [100, 200, 500, 1000, 2000, 10000],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'max_depth' : [4,8,12,None],\n",
    "            'criterion' :['gini', 'entropy']\n",
    "        }\n",
    "\n",
    "lgbm_param_grid = {\n",
    "            \"num_leaves\": [2, 8, 31, 128],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.3],\n",
    "            \"max_depth\": [-1, 2, 8],\n",
    "            \"colsample_bytree\": [0.5, 1.0],\n",
    "        }\n",
    "\n",
    "lr_param_grid = {'penalty' : ['l1', 'l2'],\n",
    "                'C' : [0.1, 0.5, 1.0, 3.0, 5.0],\n",
    "                'solver' : ['liblinear']}\n",
    "\n",
    "mlp_param_grid = {\n",
    "            \"max_iter\": [100, 200, 500, 1000],\n",
    "            \"hidden_layer_sizes\": [(10, 10, 10), (30, 20, 10), (50, 100, 50), (100)],\n",
    "            \"alpha\": [0.0001, 0.001, 0.01],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e3596faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_single_param_grid = { \n",
    "            'n_estimators': [10,50,100,200],\n",
    "            'max_depth' : [None,2,4,8,10,20],\n",
    "            'criterion' :['gini','entropy']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b17d3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_single_param_grid_trial = { \n",
    "            'n_estimators': [10],\n",
    "            'max_depth' : [50],\n",
    "            'criterion' :['gini']\n",
    "        }\n",
    "\n",
    "lr_single_param_grid = { \n",
    "            'penalty': ['l1','l2'],\n",
    "             'C' : [0.1],\n",
    "            'solver' : ['liblinear']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70339609",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "models = ['random_forest', 'logistic_regression', 'lgbm','mlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80f5b384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 11:33:27,880 INFO    Tunning MLP...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Macro-Avg  F-1 for MLP Regression Test data:  0.535104999484931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 11:41:44,106 INFO    {'alpha': 0.0001, 'hidden_layer_sizes': 100, 'max_iter': 100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Macro-Avg  F-1 for MLP Test data:  0.551988777013474\n",
      "CPU times: user 8min 16s, sys: 202 ms, total: 8min 16s\n",
      "Wall time: 8min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for model in models:\n",
    "    if model == 'random_forest':\n",
    "        logging.info(\"Tunning Random Forest...\")\n",
    "        rfc = RandomForestClassifier(random_state=42)\n",
    "        rfc.fit(train_data, train_label['anom'])  # previously we were giving x_initial, y_initial\n",
    "        pred = rfc.predict(test_data)\n",
    "        report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "        print(\"Inıtial Macro-Avg  F-1 for Random Forest on Test data: \",report_dict[\"macro avg\"][\"f1-score\"])\n",
    "        CV_rfc = GridSearchCV(estimator=rfc, param_grid=rf_param_grid, cv= 5)\n",
    "        CV_rfc.fit(train_data, train_label['anom'])\n",
    "        logging.info(CV_rfc.best_params_)\n",
    "        best_max_features = CV_rfc.best_params_['max_features']\n",
    "        best_n_estimators = CV_rfc.best_params_['n_estimators']\n",
    "        best_max_depth    = CV_rfc.best_params_['max_depth']\n",
    "        best_criterion    = CV_rfc.best_params_['criterion']\n",
    "        tuned_rfc=RandomForestClassifier(random_state=42, max_features= best_max_features, n_estimators= best_n_estimators, max_depth=best_max_depth, criterion=best_criterion)\n",
    "        tuned_rfc.fit(train_data, train_label['anom'])\n",
    "        pred = tuned_rfc.predict(test_data)\n",
    "        report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "        print(\"Tuned Macro-Avg  F-1 for Random Forest on Test data: \",report_dict[\"macro avg\"][\"f1-score\"])\n",
    "        \n",
    "    elif model == 'lgbm':\n",
    "        logging.info(\"Tunning LGBM...\")\n",
    "        train_data = train_data.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "        lgbm = LGBMClassifier(objective='multiclass', random_state=5)\n",
    "        lgbm.fit(x_initial, y_initial)\n",
    "        pred = lgbm.predict(test_data)\n",
    "        report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "        print(\"Inıtial Macro-Avg  F-1 for LGBM on Test data: \",report_dict[\"macro avg\"][\"f1-score\"])\n",
    "        CV_lgbm = GridSearchCV(estimator=lgbm, param_grid= lgbm_param_grid, cv= 5)\n",
    "        CV_lgbm.fit(x_initial, y_initial)\n",
    "        logging.info(CV_lgbm.best_params_)\n",
    "        best_n_estimators  = CV_lgbm.best_params_['n_estimators']\n",
    "        best_max_depth     = CV_lgbm.best_params_['max_depth']\n",
    "        best_learning_rate = CV_lgbm.best_params_['learning_rate']\n",
    "        best_lambda_l1     = CV_lgbm.best_params_['best_lambda_l1']\n",
    "        best_lambda_l2     = CV_lgbm.best_params_['best_lambda_l2']\n",
    "        tuned_lgbm = LGBMClassifier(random_state = 5, n_estimators= best_n_estimators, max_depth=best_max_depth, learning_rate = best_learning_rate, lambda_l1 = best_lambda_l1, lambda_l2 = best_lambda_l2 )\n",
    "        tuned_lgbm.fit(x_initial, y_initial)\n",
    "        pred = tuned_lgbm.predict(test_data)\n",
    "        report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "        print(\"Tuned Macro-Avg  F-1 for Random Forest on Test data: \",report_dict[\"macro avg\"][\"f1-score\"])\n",
    "        \n",
    "    elif model == 'logistic_regression':\n",
    "        logging.info(\"Tunning Logistic Regression...\")\n",
    "        lr = LogisticRegression(random_state=0, dual=False, max_iter=12000)\n",
    "        lr.fit(x_initial, y_initial)\n",
    "        pred = lr.predict(test_data)\n",
    "        report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "        print(\"Inıtial Macro-Avg  F-1 forLogistic Regression on Test data: \",report_dict[\"macro avg\"][\"f1-score\"])\n",
    "        CV_lr = GridSearchCV(estimator = lr, param_grid=lr_param_grid, cv= 5)\n",
    "        CV_lr.fit(x_initial, y_initial)\n",
    "        logging.info(CV_lr.best_params_)\n",
    "        best_penalty = CV_lr.best_params_['penalty']\n",
    "        best_C = CV_lr.best_params_['C']        \n",
    "        best_solver = CV_lr.best_params_['solver']\n",
    "        tuned_lr = LogisticRegression(max_iter=12000, dual=False, random_state=0, penalty= best_penalty, C = best_C, solver=best_solver)\n",
    "        tuned_lr.fit(x_initial, y_initial)\n",
    "        pred = tuned_lr.predict(test_data)\n",
    "        report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "        print(\"Tuned Macro-Avg  F-1 for Logistic Regression Test data: \",report_dict[\"macro avg\"][\"f1-score\"])\n",
    "        \n",
    "    elif model == \"mlp\":\n",
    "        logging.info(\"Tunning MLP...\")\n",
    "        mlp = MLPClassifier(random_state=1, max_iter=300).fit(x_initial, y_initial)\n",
    "        pred = mlp.predict(test_data)\n",
    "        report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "        print(\"Tuned Macro-Avg  F-1 for MLP Regression Test data: \",report_dict[\"macro avg\"][\"f1-score\"])\n",
    "        CV_mlp = GridSearchCV(estimator = mlp, param_grid=mlp_param_grid, cv= 5)\n",
    "        CV_mlp.fit(x_initial, y_initial)\n",
    "        logging.info(CV_mlp.best_params_)\n",
    "        \n",
    "        best_max_iter           = CV_mlp.best_params_['max_iter']     \n",
    "        best_hidden_layer_sizes = CV_mlp.best_params_['hidden_layer_sizes']\n",
    "        best_alpha              = CV_mlp.best_params_['alpha']\n",
    "        \n",
    "        tuned_mlp = MLPClassifier(max_iter=best_max_iter,hidden_layer_sizes = best_hidden_layer_sizes, alpha = best_alpha)\n",
    "        tuned_mlp.fit(x_initial, y_initial)\n",
    "        pred = tuned_mlp.predict(test_data)\n",
    "        report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "        print(\"Tuned Macro-Avg  F-1 for MLP Test data: \",report_dict[\"macro avg\"][\"f1-score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1205c32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 01:41:48,755 INFO    Tunning Random Forest...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inıtial Macro-Avg  F-1 for Random Forest on Test data:  0.9507058075295978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 02:02:44,711 INFO    {'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 10}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Macro-Avg  F-1 for Random Forest on Test data:  0.9522537586113472\n",
      "CPU times: user 20min 13s, sys: 39.4 s, total: 20min 53s\n",
      "Wall time: 20min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logging.info(\"Tunning Random Forest...\")\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "rfc.fit(train_data, train_label['anom'])  # previously we were giving x_initial, y_initial\n",
    "pred = rfc.predict(test_data)\n",
    "initial_report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "print(\"Inıtial Macro-Avg  F-1 for Random Forest on Test data: \",initial_report_dict[\"macro avg\"][\"f1-score\"])\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=rf_single_param_grid, cv= 5, scoring = 'f1_macro')\n",
    "CV_rfc.fit(train_data, train_label['anom'])\n",
    "logging.info(CV_rfc.best_params_)\n",
    "pred = CV_rfc.predict(test_data)\n",
    "final_report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "print(\"Tuned Macro-Avg  F-1 for Random Forest on Test data: \",final_report_dict[\"macro avg\"][\"f1-score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c550d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logging.info(f\"Tunning {MODEL}...\")\n",
    "clf.fit(train_data, train_label[\"anom\"])  # previously we were giving x_initial, y_initial\n",
    "pred = clf.predict(test_data)\n",
    "initial_report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "print(\n",
    "    f\"Inıtial Macro-Avg  F-1 for {MODEL} on Test data: \",\n",
    "    initial_report_dict[\"macro avg\"][\"f1-score\"],\n",
    ")\n",
    "CV_clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring=\"f1_macro\")\n",
    "CV_clf.fit(train_data, train_label[\"anom\"])\n",
    "logging.info(CV_clf.best_params_)\n",
    "pred = CV_clf.predict(test_data)\n",
    "final_report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "print(\n",
    "    f\"Tuned Macro-Avg  F-1 for {MODEL} on Test data: \",\n",
    "    final_report_dict[\"macro avg\"][\"f1-score\"],\n",
    ")\n",
    "CV_clf.best_params_[\"initial_f1_score\"] = initial_report_dict[\"macro avg\"][\"f1-score\"]\n",
    "CV_clf.best_params_[\"tuned_f1_score\"] = final_report_dict[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "jsonpath = conf[\"results_dir\"] / f\"{MODEL}_Best_Params.json\"\n",
    "jsonpath.write_text(json.dumps(CV_clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72de6f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 10}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_params_['initial_f1_score'] = initial_report_dict[\"macro avg\"][\"f1-score\"]\n",
    "CV_rfc.best_params_['tuned_f1_score'] = final_report_dict[\"macro avg\"][\"f1-score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6acc6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc.best_params_['tuned_f1_score'] = report_dict[\"macro avg\"][\"f1-score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bf3a359e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 8,\n",
       " 'n_estimators': 10,\n",
       " 'tuned_f1_score': 0.9522537586113472}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "053babaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 05:21:30,981 INFO    Tunning Random Forest...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inıtial Macro-Avg  F-1 for Random Forest on Test data:  0.938938633538768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 05:21:42,780 INFO    {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 10}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Macro-Avg  F-1 for Random Forest on Test data:  0.8801554781753561\n",
      "CPU times: user 11.6 s, sys: 482 ms, total: 12 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logging.info(\"Tunning Random Forest...\")\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "rfc.fit(train_data, train_label['anom'])  # previously we were giving x_initial, y_initial\n",
    "pred = rfc.predict(test_data)\n",
    "report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "print(\"Inıtial Macro-Avg  F-1 for Random Forest on Test data: \",report_dict[\"macro avg\"][\"f1-score\"])\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=rf_single_param_grid_trial, cv= 5, scoring = 'f1_macro')\n",
    "CV_rfc.fit(train_data, train_label['anom'])\n",
    "logging.info(CV_rfc.best_params_)\n",
    "pred = CV_rfc.predict(test_data)\n",
    "report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "print(\"Tuned Macro-Avg  F-1 for Random Forest on Test data: \",report_dict[\"macro avg\"][\"f1-score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2a4b5bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonpath = conf['results_dir'] / 'RandomForest_Params.json'\n",
    "jsonpath.write_text(json.dumps(CV_rfc.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb2ba18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 01:16:52,123 INFO    Tunning Logistic Regression...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inıtial Macro-Avg  F-1 for LR on Test data:  0.9492626220891143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 01:17:59,087 INFO    {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Macro-Avg  F-1 for Random Forest on Test data:  0.9294848976348679\n",
      "CPU times: user 1min 3s, sys: 3.57 s, total: 1min 7s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logging.info(\"Tunning Logistic Regression...\")\n",
    "lr = LogisticRegression(random_state=0, dual=False, max_iter=12000)\n",
    "lr.fit(train_data, train_label['anom'])  # previously we were giving x_initial, y_initial\n",
    "pred = lr.predict(test_data)\n",
    "report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "print(\"Inıtial Macro-Avg  F-1 for LR on Test data: \",report_dict[\"macro avg\"][\"f1-score\"])\n",
    "CV_lr = GridSearchCV(estimator=lr, param_grid=lr_single_param_grid, cv= 5, scoring = 'f1_macro')\n",
    "CV_lr.fit(train_data, train_label['anom'])\n",
    "logging.info(CV_lr.best_params_)\n",
    "pred = CV_lr.predict(test_data)\n",
    "report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "print(\"Tuned Macro-Avg  F-1 for Random Forest on Test data: \",report_dict[\"macro avg\"][\"f1-score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ebf2cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Macro-Avg  F-1 for MLP Test data:  0.5591269880294288\n"
     ]
    }
   ],
   "source": [
    "tuned_mlp = MLPClassifier(max_iter=1000,hidden_layer_sizes = 100, alpha = 0.0001)\n",
    "tuned_mlp.fit(x_initial, y_initial)\n",
    "pred = tuned_mlp.predict(test_data)\n",
    "report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "print(\"Tuned Macro-Avg  F-1 for MLP Test data: \",report_dict[\"macro avg\"][\"f1-score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b8acd6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inıtial Macro-Avg  F-1 for LGBM Test data:  0.9618439889706666\n",
      "CPU times: user 1min 9s, sys: 1.35 s, total: 1min 10s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(objective='multiclass')\n",
    "#renamed_train_data = train_data.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "#renamed_train_data = renamed_train_data.to_string(header=False)\n",
    "lgbm.fit(train_data.values,train_label['anom'])\n",
    "y_pred = lgbm.predict(test_data)\n",
    "report_dict = classification_report(test_label[\"anom\"], y_pred, output_dict=True)\n",
    "print(\"Inıtial Macro-Avg  F-1 for LGBM Test data: \",report_dict[\"macro avg\"][\"f1-score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c839ca08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 06:05:57,427 INFO    Tunning lgbm...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inıtial Macro-Avg  F-1 for lgbm on Test data:  0.9806170007445253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 08:31:54,666 INFO    {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 8, 'num_leaves': 128}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Macro-Avg  F-1 for lgbm on Test data:  0.9798569473448232\n",
      "CPU times: user 2h 22min 55s, sys: 3min 2s, total: 2h 25min 58s\n",
      "Wall time: 2h 25min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "MODEL = 'lgbm'\n",
    "if MODEL == \"random_forest\":\n",
    "        param_grid = {\n",
    "            \"n_estimators\": [8, 10, 20, 100, 200],\n",
    "            \"max_depth\": [None, 4, 8, 10, 20],\n",
    "            \"criterion\": [\"gini\", \"entropy\"],\n",
    "        }\n",
    "\n",
    "        clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "elif MODEL == \"logistic_regression\":\n",
    "\n",
    "    param_grid = {\n",
    "        \"penalty\": [\"l1\", \"l2\"],\n",
    "        \"C\": [0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "        \"solver\": [\"liblinear\"],\n",
    "    }\n",
    "\n",
    "    clf = LogisticRegression(random_state=0, dual=False, max_iter=12000)\n",
    "\n",
    "elif MODEL == \"mlp\":\n",
    "\n",
    "    param_grid = {\n",
    "        \"max_iter\": [100, 200, 500, 1000],\n",
    "        \"hidden_layer_sizes\": [(10, 10, 10), (30, 20, 10), (50, 100, 50), (100)],\n",
    "        \"alpha\": [0.0001, 0.001, 0.01],\n",
    "    }\n",
    "\n",
    "    clf = MLPClassifier(random_state=1)\n",
    "\n",
    "elif MODEL == \"lgbm\":\n",
    "\n",
    "    param_grid = {\n",
    "        \"num_leaves\": [2, 8, 31, 128],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.3],\n",
    "        \"max_depth\": [-1, 2, 8],\n",
    "        \"colsample_bytree\": [0.5, 1.0],\n",
    "    }\n",
    "    clf = LGBMClassifier(objective=\"multiclass\", random_state=5)\n",
    "    train_data = train_data.values\n",
    "\n",
    "else:\n",
    "    raise (\"Invalid classifier\")\n",
    "\n",
    "logging.info(f\"Tunning {MODEL}...\")\n",
    "clf.fit(train_data, train_label[\"anom\"])  # previously we were giving x_initial, y_initial\n",
    "pred = clf.predict(test_data)\n",
    "initial_report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "print(\n",
    "    f\"Inıtial Macro-Avg  F-1 for {MODEL} on Test data: \",\n",
    "    initial_report_dict[\"macro avg\"][\"f1-score\"],\n",
    ")\n",
    "CV_clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring=\"f1_macro\")\n",
    "CV_clf.fit(train_data, train_label[\"anom\"])\n",
    "logging.info(CV_clf.best_params_)\n",
    "pred = CV_clf.predict(test_data)\n",
    "final_report_dict = classification_report(test_label[\"anom\"], pred, output_dict=True)\n",
    "print(\n",
    "    f\"Tuned Macro-Avg  F-1 for {MODEL} on Test data: \",\n",
    "    final_report_dict[\"macro avg\"][\"f1-score\"],\n",
    ")\n",
    "CV_clf.best_params_[\"initial_f1_score\"] = initial_report_dict[\"macro avg\"][\"f1-score\"]\n",
    "CV_clf.best_params_[\"tuned_f1_score\"] = final_report_dict[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "jsonpath = conf[\"results_dir\"] / f\"{MODEL}_Best_Params.json\"\n",
    "jsonpath.write_text(json.dumps(CV_clf.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ead48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0407dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95739353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json \n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)-7s %(message)s',\n",
    "                    stream=sys.stderr, level=logging.INFO)\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.INFO)\n",
    "\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "\n",
    "#General ML \n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, silhouette_score,confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from modules.clustering_helpers import select_labeled_samples\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Active Learning\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling, margin_sampling, entropy_sampling\n",
    "\n",
    "\n",
    "#In-house Module Imports\n",
    "from config import Configuration \n",
    "from datasets import EclipseSampledDataset, VoltaSampledDataset\n",
    "from utils import *\n",
    "\n",
    "def random_sampling(classifier, X_pool):\n",
    "    n_samples = len(X_pool)\n",
    "    query_idx = np.random.choice(range(n_samples))\n",
    "    return query_idx, X_pool[query_idx]\n",
    "\n",
    "\n",
    "def call_FAR_function(false_alarm_rates,anomaly_miss_rates, test_label, y_pred, conf):\n",
    "    false_alarm_rate, anom_miss_rate = FAR_AMR_Calculate(\n",
    "            true_label= test_label['anom'].to_numpy(),\n",
    "            pred_label= y_pred,\n",
    "            result_dir= str(conf['results_dir']),\n",
    "            save_name= \"\",\n",
    "            save=False,\n",
    "            verbose=False,\n",
    "    )\n",
    "    false_alarm_rates.append(false_alarm_rate)\n",
    "    anomaly_miss_rates.append(anom_miss_rate)\n",
    "\n",
    "query_strategy_dict = {\n",
    "                       \"uncertainty\": uncertainty_sampling, \n",
    "                       \"margin\": margin_sampling, \n",
    "                       \"entropy\": entropy_sampling,\n",
    "                       \"random\": random_sampling\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c08ca0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIG = \"baseline_results\"  # change this\n",
    "SYSTEM = 'eclipse'  # volta or eclipse\n",
    "FE_NAME = 'mvts' #tsfresh, or mvts => It will set the EXP_NAME. Be careful. \n",
    "NUM_FEATURE = 2000  # example: 250 ,2000, 4000\n",
    "classifier_name = 'rf'\n",
    "#query_strategy = \"uncertainty\"  # \"uncertainty\", \"margin\", \"entropy\", \"random\"\n",
    "CV_INDEX = 0  # it can be integer value within the range 0 1 2 3 4\n",
    "#repeat_num = 0\n",
    "#query_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbb06c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 10:19:52,502 WARNING Results will be generated in baseline_results, double check please!\n"
     ]
    }
   ],
   "source": [
    "#Constants\n",
    "FS_NAME = \"CHI\"\n",
    "#method = \"random\" if query_strategy == 'random' else \"active_learning\"\n",
    "num_samples_per_pair = 1\n",
    "OUTPUT_DIR = f'/projectnb/peaclab-mon/{user}/active_learning_experiments_final_hdfs'\n",
    "EXP_NAME = f'{FE_NAME}_experiments'\n",
    "FEATURE_SELECTION = False\n",
    "SCALER = 'None' #For now, do the scaling inside the notebook, then you can move that to the class function\n",
    "\n",
    "logging.warning('Results will be generated in {}, double check please!'.format(MODEL_CONFIG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2289d7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 10:19:56,099 WARNING You set windowing False, but you are trying to define window_size parameter, it is automatically set to 0. Please double check.\n",
      "2022-04-25 10:19:56,099 INFO    Setting directory names\n",
      "2022-04-25 10:19:56,108 INFO    Saving configuration as CSV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The configuration used for this run:\n",
      "# {'cv_fold': 0,\n",
      "#  'exp_name': 'mvts_experiments',\n",
      "#  'experiment_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments_final_hdfs/eclipse/mvts_experiments'),\n",
      "#  'feature_extract': False,\n",
      "#  'feature_select': False,\n",
      "#  'hdf_data_path': PosixPath('/projectnb/peaclab-mon/aksar/datasets/eclipse_final_hdfs'),\n",
      "#  'metadata_path': None,\n",
      "#  'model_config': 'baseline_results',\n",
      "#  'model_config_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments_final_hdfs/eclipse/mvts_experiments/CV_0/baseline_results'),\n",
      "#  'model_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments_final_hdfs/eclipse/mvts_experiments/CV_0/baseline_results/model'),\n",
      "#  'num_split': 5,\n",
      "#  'operation': 'read',\n",
      "#  'output_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments_final_hdfs/eclipse'),\n",
      "#  'plots_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments_final_hdfs/eclipse/mvts_experiments/CV_0/baseline_results/model/plots'),\n",
      "#  'processed_ldms_data_path': None,\n",
      "#  'raw_ldms_data_path': None,\n",
      "#  'results_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments_final_hdfs/eclipse/mvts_experiments/CV_0/baseline_results/results'),\n",
      "#  'runtime_testing_dir': None,\n",
      "#  'system': 'eclipse',\n",
      "#  'window_size': 0,\n",
      "#  'windowing': False}\n"
     ]
    }
   ],
   "source": [
    "conf = Configuration(ipython=True,\n",
    "                     overrides={\n",
    "                         'output_dir': Path(OUTPUT_DIR), #change\n",
    "                         'system' : SYSTEM,\n",
    "                         'exp_name':EXP_NAME,                                                  \n",
    "                         'cv_fold':CV_INDEX, \n",
    "                         'model_config': MODEL_CONFIG,\n",
    "                     })\n",
    "\n",
    "with open(str(conf['experiment_dir']) + '/anom_dict.json') as f:\n",
    "    ANOM_DICT = json.load(f)\n",
    "with open(str(conf['experiment_dir']) + '/app_dict.json') as f:\n",
    "    APP_DICT = json.load(f) \n",
    "    \n",
    "APP_REVERSE_DICT = {}\n",
    "for app_name, app_encoding in APP_DICT.items():\n",
    "    APP_REVERSE_DICT[app_encoding] = app_name    \n",
    "\n",
    "ANOM_REVERSE_DICT = {}\n",
    "for anom_name, anom_encoding in ANOM_DICT.items():\n",
    "    ANOM_REVERSE_DICT[anom_encoding] = anom_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a729ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SYSTEM == 'eclipse':\n",
    "    eclipseDataset = EclipseSampledDataset(conf)\n",
    "    train_data, train_label, test_data, test_label = eclipseDataset.load_dataset(scaler=SCALER,\n",
    "                                                                                 cv_fold=CV_INDEX,\n",
    "                                                                                 borghesi=False, \n",
    "                                                                                 mvts=True if FE_NAME == 'mvts' else False, \n",
    "                                                                                 tsfresh=True if FE_NAME == 'tsfresh' else False)\n",
    "\n",
    "elif SYSTEM == 'volta':\n",
    "    voltaDataset = VoltaSampledDataset(conf)\n",
    "    train_data, train_label, test_data, test_label = voltaDataset.load_dataset(scaler=SCALER,\n",
    "                                                                               cv_fold=CV_INDEX,\n",
    "                                                                               borghesi=False,\n",
    "                                                                               mvts=True if FE_NAME == 'mvts' else False,\n",
    "                                                                               tsfresh=True if FE_NAME == 'tsfresh' else False)\n",
    "\n",
    "assert list(train_data.index) == list(train_label.index) #check the order of the labels     \n",
    "assert list(test_data.index) == list(test_label.index) #check the order of the labels    \n",
    "\n",
    "if FEATURE_SELECTION:\n",
    "    selected_features = pd.read_csv(conf['experiment_dir'] / 'selected_features.csv')\n",
    "    train_data = train_data[list(selected_features['0'].values)]\n",
    "    test_data = test_data[list(selected_features['0'].values)]\n",
    "    \n",
    "train_label['anom_names'] = train_label.apply(lambda x: ANOM_REVERSE_DICT[x['anom']], axis=1)\n",
    "train_label['app_names']=train_label['app'].apply(lambda x: APP_REVERSE_DICT[x])\n",
    "test_label['anom_names'] = test_label.apply(lambda x: ANOM_REVERSE_DICT[x['anom']], axis=1)\n",
    "test_label['app_names']=test_label['app'].apply(lambda x: APP_REVERSE_DICT[x])\n",
    "\n",
    "all_data = pd.concat([train_data, test_data])\n",
    "all_data = all_data.dropna(axis=1, how='any')\n",
    "all_label = pd.concat([train_label,test_label])\n",
    "\n",
    "train_data = all_data.loc[train_label.index]\n",
    "test_data = all_data.loc[test_label.index]\n",
    "    \n",
    "logging.info(\"Train data shape %s\",train_data.shape)\n",
    "logging.info(\"Train label shape %s\",train_label.shape)\n",
    "logging.info(\"Test data shape %s\",test_data.shape)  \n",
    "logging.info(\"Test label shape %s\",test_label.shape)\n",
    "\n",
    "logging.info(\"Train data label dist: \\n%s\",train_label['anom'].value_counts())\n",
    "logging.info(\"Test data label dist: \\n%s\",test_label['anom'].value_counts())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e0b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALER = 'MinMax'\n",
    "\n",
    "if SCALER == 'MinMax':\n",
    "    \n",
    "    minmax_scaler = MinMaxScaler().fit(train_data)\n",
    "    train_data = pd.DataFrame(minmax_scaler.transform(train_data),columns=train_data.columns,index=train_data.index)\n",
    "    test_data = pd.DataFrame(minmax_scaler.transform(test_data),columns=test_data.columns,index=test_data.index)\n",
    "    \n",
    "elif SCALER == 'Standard':\n",
    "    \n",
    "    # Standardize data (per feature Z-normalization, i.e. zero-mean and unit variance)        \n",
    "    scaler = StandardScaler().fit(train_data)\n",
    "    train_data = pd.DataFrame(scaler.transform(train_data),columns=train_data.columns,index=train_data.index)\n",
    "    test_data = pd.DataFrame(scaler.transform(test_data),columns=test_data.columns,index=test_data.index)  \n",
    "    \n",
    "#Implement new feature selection strategies below\n",
    "if FS_NAME == 'CHI':\n",
    "    \n",
    "    selector = SelectKBest(chi2, k=NUM_FEATURE)\n",
    "    selector.fit(train_data,train_label['anom'])\n",
    "    train_data = train_data[train_data.columns[selector.get_support(indices=True)]]\n",
    "    selected_columns = train_data.columns\n",
    "    test_data = test_data[test_data.columns & selected_columns]\n",
    "    \n",
    "elif FS_NAME == 'TSFRESH':\n",
    "    logging.warning(\"NUM_FEATURE parameter will be overwritten by the automatic selection process\")\n",
    "    \n",
    "    y_train = train_label['anom']\n",
    "    X_train = train_data\n",
    "\n",
    "    relevant_features = set()\n",
    "\n",
    "    for label in y_train.unique():\n",
    "        y_train_binary = y_train == label\n",
    "        X_train_filtered = tsfresh.select_features(X_train, y_train_binary)\n",
    "        print(\"Number of relevant features for class {}: {}/{}\".format(label, X_train_filtered.shape[1], X_train.shape[1]))\n",
    "        relevant_features = relevant_features.union(set(X_train_filtered.columns))    \n",
    "    train_data = train_data[relevant_features]\n",
    "    test_data = test_data[relevant_features]\n",
    "    NUM_FEATURE = len(relevant_features)\n",
    "    \n",
    "elif FS_NAME == 'NONE':\n",
    "    logging.info(\"No feature selection strategy is specified, will be using all features\")\n",
    "    NUM_FEATURE = len(train_data.columns)\n",
    "    \n",
    "logging.info(train_data.shape)\n",
    "logging.info(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c97f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cbb7525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.fit(train_data, train_label['anom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3651a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = clf_rf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5b21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_preds, test_label['anom']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a3ad794",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_all_data = pd.concat([train_data, test_data])\n",
    "all_labels = pd.concat([train_label,test_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4525bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(scaled_all_data.index) == list(all_labels.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7d0b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d96912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccee7add",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf_rf, scaled_all_data, all_labels['anom'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6ad2cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99002849, 0.99246896, 0.98860167, 0.99104417, 0.99165479])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e4127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d067d786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2064ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

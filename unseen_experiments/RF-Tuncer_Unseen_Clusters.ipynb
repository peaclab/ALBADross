{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddeee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5926dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a3c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,sys\n",
    "from pathlib import Path\n",
    "import json \n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)-7s %(message)s',\n",
    "                    stream=sys.stderr, level=logging.INFO)\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.INFO)\n",
    "\n",
    "#General ML \n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, silhouette_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from itertools import combinations\n",
    "\n",
    "#In-house Module Imports\n",
    "from config import Configuration \n",
    "from datasets import EclipseSampledDataset, VoltaSampledDataset\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5af1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"aksar\"\n",
    "logging.warning(f'Are you sure that you are: {user}?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685d6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update these if you are not the desired user\n",
    "OUTPUT_DIR = f'/projectnb/peaclab-mon/{user}/unseen_experiments'\n",
    "SYSTEM = 'volta'\n",
    "EXP_NAME = 'tpds_experiments'\n",
    "CV_INDEX = 0\n",
    "FEATURE_SELECTION = False\n",
    "SCALER = 'None' #For now, do the scaling inside the notebook, then you can move that to the class function\n",
    "MODEL_CONFIG = 'experiment_3' #rf_tuncer or rf_tuncer_worst_case\n",
    "logging.warning('Results will be generated in {}, double check please!'.format(MODEL_CONFIG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38912d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Configuration(ipython=True,\n",
    "                     overrides={\n",
    "                         'output_dir': Path(OUTPUT_DIR), #change\n",
    "                         'system' : SYSTEM,\n",
    "                         'exp_name':EXP_NAME,                                                  \n",
    "                         'cv_fold':CV_INDEX, \n",
    "                         'model_config': MODEL_CONFIG,\n",
    "                     })\n",
    "\n",
    "with open(str(conf['experiment_dir']) + '/anom_dict.json') as f:\n",
    "    ANOM_DICT = json.load(f)\n",
    "with open(str(conf['experiment_dir']) + '/app_dict.json') as f:\n",
    "    APP_DICT = json.load(f)    \n",
    "    \n",
    "APP_REVERSE_DICT = {}\n",
    "for app_name, app_encoding in APP_DICT.items():\n",
    "    APP_REVERSE_DICT[app_encoding] = app_name    \n",
    "\n",
    "ANOM_REVERSE_DICT = {}\n",
    "for anom_name, anom_encoding in ANOM_DICT.items():\n",
    "    ANOM_REVERSE_DICT[anom_encoding] = anom_name        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0bc918",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SYSTEM == 'eclipse':\n",
    "    \n",
    "    eclipseDataset = EclipseSampledDataset(conf)\n",
    "    train_data, train_label, test_data, test_label = eclipseDataset.load_dataset(scaler=SCALER,borghesi=False,tsfresh = True)\n",
    "\n",
    "elif SYSTEM == 'volta':\n",
    "    voltaDataset = VoltaSampledDataset(conf)\n",
    "    train_data, train_label, test_data, test_label = voltaDataset.load_dataset(scaler=SCALER,borghesi=False)\n",
    "    \n",
    "assert list(train_data.index) == list(train_label.index) #check the order of the labels     \n",
    "assert list(test_data.index) == list(test_label.index) #check the order of the labels    \n",
    "\n",
    "if FEATURE_SELECTION:\n",
    "    selected_features = pd.read_csv(conf['experiment_dir'] / 'selected_features.csv')\n",
    "    train_data = train_data[list(selected_features['0'].values)]\n",
    "    test_data = test_data[list(selected_features['0'].values)]\n",
    "    \n",
    "train_label['anom_names'] = train_label.apply(lambda x: ANOM_REVERSE_DICT[x['anom']], axis=1)\n",
    "train_label['app_names']=train_label['app'].apply(lambda x: APP_REVERSE_DICT[x])\n",
    "test_label['anom_names'] = test_label.apply(lambda x: ANOM_REVERSE_DICT[x['anom']], axis=1)\n",
    "test_label['app_names']=test_label['app'].apply(lambda x: APP_REVERSE_DICT[x])\n",
    "\n",
    "all_data = pd.concat([train_data, test_data])\n",
    "all_data = all_data.dropna(axis=1, how='any')\n",
    "all_label = pd.concat([train_label,test_label])\n",
    "\n",
    "train_data = all_data.loc[train_label.index]\n",
    "test_data = all_data.loc[test_label.index]\n",
    "    \n",
    "logging.info(\"Train data shape %s\",train_data.shape)\n",
    "logging.info(\"Train label shape %s\",train_label.shape)\n",
    "logging.info(\"Test data shape %s\",test_data.shape)  \n",
    "logging.info(\"Test label shape %s\",test_label.shape)\n",
    "\n",
    "logging.info(\"Train data label dist: \\n%s\",train_label['anom'].value_counts())\n",
    "logging.info(\"Test data label dist: \\n%s\",test_label['anom'].value_counts())        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f6964",
   "metadata": {},
   "source": [
    "## Unknown App Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALER = 'MinMax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "nas_apps = ['lu','sp','ft','bt','cg','mg']\n",
    "mantevo_apps = ['miniMD','CoMD','miniGhost','miniAMR']\n",
    "other_apps = ['kripke']\n",
    "\n",
    "all_app_names = list(APP_DICT.keys())\n",
    "\n",
    "assert set(nas_apps + mantevo_apps + other_apps) == set(all_app_names)\n",
    "\n",
    "\n",
    "cluster_one = ['ft','cg','mg'] #126\n",
    "cluster_two = ['miniAMR','lu','miniGhost'] #126\n",
    "cluster_three = ['sp','bt','miniMD','kripke','CoMD'] #max 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_app_groups = []\n",
    "all_test_app_sets = []\n",
    "for cluster in [cluster_one,cluster_two,cluster_three]:    \n",
    "    all_test_app_groups.append(cluster)\n",
    "    all_test_app_sets.append(set(cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This doesn't hold the unique combinations, however it should have the total number\n",
    "train_app_combinations = []\n",
    "\n",
    "#90 different test_apps combination\n",
    "for test_apps in all_test_app_groups:\n",
    "    \n",
    "    train_apps_all = list(set(all_app_names) - set(test_apps))\n",
    "    #logging.info(\"Test apps: %s\", test_apps)\n",
    "    #logging.info(\"All Train apps: %s\", train_apps_all)\n",
    "    \n",
    "    num_train_unknowns = [2,4,6]\n",
    "\n",
    "    #126 or 31 different train_apps combination\n",
    "    for num_train_unknown in num_train_unknowns:\n",
    "        for train_apps in combinations(train_apps_all, num_train_unknown):\n",
    "            train_app_combinations.append(train_apps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e985cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code blocks read the processed filenames so far and creates a dict using (train_apps,test_apps) as a key\n",
    "It can also detect cases which are processed multiple times with different names\n",
    "\"\"\"\n",
    "\n",
    "not_covered_combinations = []\n",
    "unique_counter_dict = {}\n",
    "extra_filenames = []\n",
    "delete_extra_files = False\n",
    "\n",
    "for file in listdir(conf['results_dir']):\n",
    "    \n",
    "    if \"result_dict\" in file:\n",
    "\n",
    "        filename = file.split('.')[0]\n",
    "        splitted_filename = file.split('#')    \n",
    "\n",
    "        train_apps = set(splitted_filename[0].split(':')[1].split(\"-\"))\n",
    "        test_apps = set(splitted_filename[1].split(':')[1].split(\"-\"))\n",
    "        \n",
    "        if not (frozenset(train_apps),frozenset(test_apps)) in unique_counter_dict:\n",
    "            unique_counter_dict[(frozenset(train_apps),frozenset(test_apps))] = 1\n",
    "        else:\n",
    "            unique_counter_dict[(frozenset(train_apps),frozenset(test_apps))] += 1\n",
    "            extra_filenames.append(file)\n",
    "                    \n",
    "        if (not test_apps in all_test_app_sets) and (not train_apps in train_app_combinations):\n",
    "            not_covered_combinations.append([train_apps,test_apps])\n",
    "                        \n",
    "sorted_unique_counter_dict = dict(sorted(unique_counter_dict.items(), key=lambda x: x[1], reverse=True))            \n",
    "\n",
    "if delete_extra_files:\n",
    "    \n",
    "    for filename in extra_filenames:\n",
    "\n",
    "        generic_filename = \"#\".join(filename.split(\"#\")[:-1])\n",
    "\n",
    "        os.remove(Path(conf['results_dir']) / filename)\n",
    "        os.remove(Path(conf['results_dir']) / (generic_filename + \"#alert_dict.json\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for test_apps in all_test_app_groups:\n",
    "    \n",
    "    train_apps_all = list(set(all_app_names) - set(test_apps))\n",
    "    logging.info(\"Test apps: %s\", test_apps)\n",
    "    logging.info(\"All Train apps: %s\", train_apps_all)\n",
    "    \n",
    "    test_apps_label = all_label[all_label['app_names'].isin(test_apps)]\n",
    "    assert set(test_apps_label['app_names'].unique()) == set(test_apps)\n",
    "    \n",
    "    test_apps_data = all_data.loc[test_apps_label.index]\n",
    "    assert list(test_apps_data.index) == list(test_apps_label.index) #check the order of the labels       \n",
    "    \n",
    "    num_train_unknowns = [2,4,6]\n",
    "                \n",
    "    for num_train_unknown in num_train_unknowns:    \n",
    "        \n",
    "        for train_apps_selected in combinations(train_apps_all, num_train_unknown):        \n",
    "            \n",
    "            train_apps_selected = list(train_apps_selected)\n",
    "            logging.info(\"Selected train apps: %s\", train_apps_selected)\n",
    "                        \n",
    "            if not (frozenset(train_apps_selected),frozenset(test_apps)) in unique_counter_dict:                \n",
    "            \n",
    "                train_apps_label = all_label[all_label['app_names'].isin(train_apps_selected)]\n",
    "                train_apps_data = all_data.loc[train_apps_label.index]\n",
    "                assert list(train_apps_data.index) == list(train_apps_label.index) #check the order of the labels \n",
    "\n",
    "                if SCALER == 'MinMax':\n",
    "\n",
    "                    scaler = MinMaxScaler()    \n",
    "\n",
    "                elif SCALER == 'Standard':\n",
    "\n",
    "                    scaler = StandardScaler()\n",
    "                    \n",
    "                clf = RandomForestClassifier(random_state=0)\n",
    "                \n",
    "                pipeline = Pipeline([('transformer', scaler), ('estimator', clf)])  \n",
    "                \n",
    "                fit_clf = pipeline.fit(train_apps_data, train_apps_label['anom'])\n",
    "\n",
    "                pred_test = pipeline.predict(test_apps_data)                \n",
    "                logging.info(\"\\n %s\",classification_report(test_apps_label['anom'],pred_test, target_names=ANOM_DICT))\n",
    "                \n",
    "                result_filename = \"train:\" + \"-\".join(train_apps_selected) + \"#test:\" + \"-\".join(test_apps) \\\n",
    "                            + \"#model:\" + clf.__class__.__name__ + \"#cv:\" + str(CV_INDEX)                    \n",
    "                logging.info(result_filename)\n",
    "                result_dict = classification_report(test_apps_label['anom'],pred_test, target_names=ANOM_DICT,output_dict=True)\n",
    "\n",
    "                with open(Path(conf['results_dir']) / (result_filename + \"#result_dict.json\"), \"w\") as fp:\n",
    "                    json.dump(result_dict, fp)\n",
    "\n",
    "                FAR_AMR_Calculate(true_label=test_apps_label['anom'],pred_label=pred_test,\n",
    "                                  result_dir=conf['results_dir'],\n",
    "                                  save_name=result_filename,save=True)                                   \n",
    "            else: \n",
    "                counter += 1\n",
    "                logging.info(\"File exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e385c1f",
   "metadata": {},
   "source": [
    "### 5-fold CV Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0907a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALER = 'MinMax'\n",
    "\n",
    "if SCALER == 'MinMax':\n",
    "    \n",
    "    scaler = MinMaxScaler()    \n",
    "\n",
    "elif SCALER == 'Standard':\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffca0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['precision_macro', 'recall_macro', 'f1_macro', 'f1_weighted']\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "scores = cross_validate(pipeline, all_data, all_label['anom'].values,                         \n",
    "                        cv=skf, \n",
    "                        scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c5118",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
